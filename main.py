# -*- coding: utf-8 -*-
"""Main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xIgkXw2xK8muOoOIPGmwnwA9DUv7tnHd

@article{bailo2018efficient,
  title={Efficient adaptive non-maximal suppression algorithms for homogeneous spatial keypoint distribution},
  author={Bailo, Oleksandr and Rameau, Francois and Joo, Kyungdon and Park, Jinsun and Bogdan, Oleksandr and Kweon, In So},
  journal={Pattern Recognition Letters},
  volume={106},
  pages={53--60},
  year={2018},
  publisher={Elsevier}
}
"""

#!pip install opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17

#!pip install pyro-ppl

#from google.colab import drive
#drive.mount('/content/drive')

# this code section is from: https://github.com/BAILOOL/ANMS-Codes
# Adaptive Non-Maximal supression is used to evenly distribute feature points
import cv2 as cv
import sys
import numpy as np
import matplotlib.pyplot as plt
import argparse
from random import shuffle
import logging

import torch

import pyro
import pyro.distributions as dist
import pyro.poutine as poutine
from pyro.infer import MCMC, NUTS
import pptk
#from google.colab.patches import cv2_imshow
import math
import copy
from ssc import *
from helper import *
import open3d as o3d



def ssc(keypoints, num_ret_points, tolerance, cols, rows):
    exp1 = rows + cols + 2 * num_ret_points
    exp2 = 4 * cols + 4 * num_ret_points + 4 * rows * num_ret_points + rows * rows + cols * cols - \
           2 * rows * cols + 4 * rows * cols * num_ret_points
    exp3 = math.sqrt(exp2)
    exp4 = num_ret_points - 1

    sol1 = -round(float(exp1 + exp3) / exp4)  # first solution
    sol2 = -round(float(exp1 - exp3) / exp4)  # second solution

    high = sol1 if (sol1 > sol2) else sol2  # binary search range initialization with positive solution
    low = math.floor(math.sqrt(len(keypoints) / num_ret_points))

    prev_width = -1
    selected_keypoints = []
    result_list = []
    result = []
    complete = False
    k = num_ret_points
    k_min = round(k - (k * tolerance))
    k_max = round(k + (k * tolerance))

    while not complete:
        width = low + (high - low) / 2
        if width == prev_width or low > high:  # needed to reassure the same radius is not repeated again
            result_list = result  # return the keypoints from the previous iteration
            break

        c = width / 2  # initializing Grid
        num_cell_cols = int(math.floor(cols / c))
        num_cell_rows = int(math.floor(rows / c))
        covered_vec = [[False for _ in range(num_cell_cols + 1)] for _ in range(num_cell_rows + 1)]
        result = []

        for i in range(len(keypoints)):
            row = int(math.floor(keypoints[i].pt[1] / c))  # get position of the cell current point is located at
            col = int(math.floor(keypoints[i].pt[0] / c))
            if not covered_vec[row][col]:  # if the cell is not covered
                result.append(i)
                # get range which current radius is covering
                row_min = int((row - math.floor(width / c)) if ((row - math.floor(width / c)) >= 0) else 0)
                row_max = int(
                    (row + math.floor(width / c)) if (
                            (row + math.floor(width / c)) <= num_cell_rows) else num_cell_rows)
                col_min = int((col - math.floor(width / c)) if ((col - math.floor(width / c)) >= 0) else 0)
                col_max = int(
                    (col + math.floor(width / c)) if (
                            (col + math.floor(width / c)) <= num_cell_cols) else num_cell_cols)
                for rowToCov in range(row_min, row_max + 1):
                    for colToCov in range(col_min, col_max + 1):
                        if not covered_vec[rowToCov][colToCov]:
                            # cover cells within the square bounding box with width w
                            covered_vec[rowToCov][colToCov] = True

        if k_min <= len(result) <= k_max:  # solution found
            result_list = result
            complete = True
        elif len(result) < k_min:
            high = width - 1  # update binary search range
        else:
            low = width + 1
        prev_width = width

    for i in range(len(result_list)):
        selected_keypoints.append(keypoints[result_list[i]])

    return selected_keypoints

"""First, load left and right (multiple images later on)"""

fx = 499.70
fy = 502.22
cx = 315.28
cy = 240.62
K = np.array([[fx , 0 , cx]  ,[0  ,fy , cy]  ,[0  ,0  ,1]])


left_orig = cv.imread("left.jpg")
left_orig = cv.GaussianBlur(left_orig,(111,111),10)
cv.imwrite("left_orig.jpg",left_orig)

left = cv.imread("left.jpg",cv.IMREAD_GRAYSCALE)
right = cv.imread("right.jpg",cv.IMREAD_GRAYSCALE)

left = cv.GaussianBlur(left,(5,5),1)
right = cv.GaussianBlur(right,(5,5),1)

"""For all images, Extract feature points"""

sift = cv.xfeatures2d.SIFT_create()

# find the keypoints with ORB
# compute the descriptors with ORB
kpL = sift.detect(left,None)

shuffle(kpL)  # simulating sorting by score with random shuffle
s_kpL = ssc(kpL, 1000, 0.01, left.shape[1], left.shape[0])
#s_kpL = kpL

s_kpL,desL = sift.compute(left,s_kpL)

# draw only keypoints location,not size and orientation
left2 = cv.drawKeypoints(left, s_kpL, None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

siftR = cv.xfeatures2d.SIFT_create()

# find the keypoints with ORB
kpR = sift.detect(right,None)

shuffle(kpR)
s_kpR = ssc(kpR, 1000, 0.01, right.shape[1], right.shape[0])
#s_kpR = kpR

s_kpR,desR = sift.compute(right,s_kpR)


# draw only keypoints location,not size and orientation
right2 = cv.drawKeypoints(right, s_kpR, None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

desL = np.float32(desL)
desR = np.float32(desR)

print("got points")

# FLANN parameters
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)   # or pass empty dictionary

flann = cv.FlannBasedMatcher(index_params,search_params)

# Sort them in the order of their distance.
matches = flann.knnMatch(desL,desR,k=2)
# Need to draw only good matches, so create a mask
matchesMask = [[0,0] for i in range(len(matches))]
# ratio test as per Lowe's paper
newmatches = []
for i,(m,n) in enumerate(matches):
    if m.distance < 0.7*n.distance: # == 서로 비슷하면
        matchesMask[i]=[1,0]
        newmatches.append([m,n])        


draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = matchesMask,
                   flags = cv.DrawMatchesFlags_DEFAULT)

print(len(newmatches))

img3 = cv.drawMatchesKnn(left2,s_kpL,right2,s_kpR,matches,None,**draw_params)
cv.imwrite("img.jpg",img3)

"""After getting matching points, set up Matrix D"""

# D = [[z11x11 z12x12 ... z1nx1n] , [z21x21 z22x22 ... z2nx2n]]

# Initialize lists
list_kpL = []
list_kpR = []

# For each match...
sumx = 0
sumy = 0
for mat_2 in newmatches:
    mat = mat_2[0]
    # Get the matching keypoints for each of the images
    img1_idx = mat.queryIdx
    img2_idx = mat.trainIdx

    # x - columns
    # y - rows
    # Get the coordinates
    (x1, y1) = s_kpL[img1_idx].pt
    (x2, y2) = s_kpR[img2_idx].pt

    # Append to each list
    list_kpL.append((x1, y1,1))
    list_kpR.append((x2, y2,1))

ptsL = np.array(list_kpL)
ptsR = np.array(list_kpR)

#ptsL ptsR normalization 실행
L_mean = (sum(ptsL)/len(ptsL))
R_mean = (sum(ptsR)/len(ptsR))

#ptsL = [(x - L_mean) for x in ptsL]
#ptsR = [(x - R_mean) for x in ptsR]

ptsL = np.array(ptsL)
ptsR = np.array(ptsR)

#ptsL = cv.undistortPoints(ptsL, K,None)
#ptsR = cv.undistortPoints(ptsR, K,None)

F, mask = cv.findFundamentalMat(ptsL,ptsR,cv.FM_LMEDS)

# We select only inlier points

#ptsL = ptsL[mask.ravel()==1]
#ptsR = ptsR[mask.ravel()==1] 
# // MCMC 로 바꿔버릴 수 있다

print(ptsL.shape)



"""After obtaining matches from two images, Pyro will be used to do projective factorization"""

torch.cuda.is_available()

extr_L = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])

#F = torch.from_numpy(F).cuda()


E = np.matmul(np.matmul(np.transpose(K), F), K)

print(K)

ptsL2 = ptsL[:,0:2]
ptsR2 = ptsR[:,0:2]

retval, R, t, mask = cv.recoverPose(E, ptsL2, ptsR2, K)
#ptsL = ptsL[mask.ravel()!=0]
#ptsR = ptsR[mask.ravel()!=0]

ptsL2 = ptsL[:,0:2]
ptsR2 = ptsR[:,0:2]


extr_R = np.concatenate((R,t),axis = 1)

print("Rotation and translation")
print(R)
print(t)

P_L = np.matmul(K,extr_L)
P_R = np.matmul(K,extr_R)

print(P_L)
print(P_R)

ptsL2 = np.transpose(ptsL2)
ptsR2 = np.transpose(ptsR2)


PTS = cv.triangulatePoints(P_R,P_L,ptsR2,ptsL2)

PTS /= PTS[3]

#U,S,V = torch.svd(D, some=False, compute_uv=True, out=None)
#print(U.shape)
P = torch.from_numpy(np.concatenate((P_L,P_R),axis = 0)).cuda()

D_list = [ptsL,ptsR]
Darr = np.array(D_list).reshape(6,-1)
D = torch.from_numpy(Darr).cuda()

p = PTS[3,:]
xn = PTS[0,:] 
yn = PTS[1,:] 
zn = PTS[2,:] 

x = []
y = []
z = []
xyz = []
xyzH = []
colors = []
L_pos = []
idx = 0
print(left_orig.shape)

maxwidth = left_orig.shape[0]
maxheight = left_orig.shape[1]
numfilter = 0
for (i, j, k) in zip(xn, yn, zn):
    posx = ptsL2[0][idx] + L_mean[0]
    posy = ptsL2[1][idx] + L_mean[1]
    
    if(np.sqrt(i*i + j*j + k*k) < 10000 and posx < maxheight and posy < maxwidth and posx >= 0 and posy >= 0):
        x.append(i)
        y.append(j)
        z.append(k)
        
        L_pos.append([posx,posy])
        xyz.append([i,j,k])
        xyzH.append([i,j,k,1])
        
        col = left_orig[int(posy),int(posx)].tolist()
        B = col[0]
        G = col[1]
        R = col[2]
        col = [R,G,B]
        col = [float(i)/255.0 for i in col]
        colors.append(col)
    else:
        numfilter += 1
    idx += 1

print("Filtered:" + str(numfilter))

pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(xyz)
pcd.colors = o3d.utility.Vector3dVector(colors)
o3d.io.write_point_cloud("sync.ply", pcd)
pcd_load = o3d.io.read_point_cloud("sync.ply")
xyz_load = np.asarray(pcd_load.points)
o3d.visualization.draw_geometries([pcd_load],width = 1000,height = 1000)




xyzH = np.array(xyzH)

# x = PX 이용해서 나타내보면?
print()
xyzH = np.transpose(np.array(xyzH))

rec_points_L = np.transpose(np.matmul(P_L,xyzH))
rec_points_R = np.transpose(np.matmul(P_R,xyzH))
rec_points_L = (rec_points_L)/rec_points_L[:,2:3] + L_mean
rec_points_R = (rec_points_R)/rec_points_R[:,2:3] + R_mean
rec_points_L = rec_points_L[:,0:2]
rec_points_R = rec_points_R[:,0:2]

print(rec_points_L.shape)


#Reprojection 에러들을 확인해보자.
L_pos = np.array(L_pos)
im = plt.imread("left.jpg")
implot = plt.imshow(im)
plt.scatter(rec_points_L[:,0],rec_points_L[:,1], c='r', s=5)
plt.scatter(L_pos[:,0],L_pos[:,1], c='g', s=5)
plt.scatter(rec_points_R[:,0],rec_points_R[:,1], c='b', s=2)

plt.show()



print("bp")

# x = PX

# sample P and X from some distribution
# observe x = PX


# Generate P and X using triangulation, getting somewhat good prior to begin with



print(D.shape)
torch.set_default_tensor_type('torch.cuda.FloatTensor')
logging.basicConfig(format='%(message)s', level=logging.INFO)
pyro.enable_validation(__debug__)
pyro.set_rng_seed(0)

device = 'cuda:0'

# D = m x n,        P = 3m x 4,         X = 4 x n
def model(sigma):
    Px = pyro.sample('P', dist.Normal(P, torch.ones([D.shape[0],4]).cuda()))
    #Px = P
    X = pyro.sample('X', dist.Normal(torch.from_numpy(PTS).cuda(), torch.ones([4,D.shape[1]]).cuda()))
    res = torch.mm(Px,X).cuda()

    return res

def conditioned_model(model, sigma, y):
    return poutine.condition(model, data={"obs": y})(sigma)

nuts_kernel = NUTS(conditioned_model, adapt_step_size=True)
mcmc = MCMC(nuts_kernel,
            num_samples=1000,
            warmup_steps=1000,
             mp_context="spawn")
mcmc_run = mcmc.run(model, 1, D)

#MCMC 는 느리므로, SVI 를 이용해보자?

#posterior = EmpiricalMarginal(mcmc_run, 'beta')
res = mcmc.get_samples()


#P = res['P'].cpu()
X = res['X'].mean(0).cpu()
# 89 포인트
p = X[3,:]
xn = X[0,:] 
yn = X[1,:] 
zn = X[2,:] 

xn = torch.div(xn, p).tolist()
yn = torch.div(yn, p).tolist()
zn = torch.div(zn, p).tolist()

x = []
y = []
z = []
xyz = []
colors = []
idx = 0

numfilter = 0

for (i, j, k) in zip(xn, yn, zn):
    posx = ptsL2[0][idx] + L_mean[0]
    posy = ptsL2[1][idx] + L_mean[1]

    if(np.sqrt(i*i + j*j + k*k) < 200 and posx < maxwidth and posy < maxheight and posx >= 0 and posy >= 0 and k > 0):
        #if(np.sqrt(i*i + j*j + k*k) < 30):
        x.append(i)
        y.append(j)
        z.append(k)
        
        xyz.append([i,j,k])

        col = left_orig[int(posy),int(posx)].tolist()
        B = col[0]
        G = col[1]
        R = col[2]
        col = [R,G,B]
        col = [float(i)/255.0 for i in col]
        colors.append(col)
    else:
        numfilter += 1
    idx += 1

print("Filtered:" + str(numfilter))

pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(xyz)
pcd.colors = o3d.utility.Vector3dVector(colors)
o3d.io.write_point_cloud("sync.ply", pcd)
pcd_load = o3d.io.read_point_cloud("sync.ply")
xyz_load = np.asarray(pcd_load.points)
o3d.visualization.draw_geometries([pcd_load],width = 1000,height = 1000)

print("bp")