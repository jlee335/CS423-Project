# -*- coding: utf-8 -*-
"""Main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xIgkXw2xK8muOoOIPGmwnwA9DUv7tnHd

@article{bailo2018efficient,
  title={Efficient adaptive non-maximal suppression algorithms for homogeneous spatial keypoint distribution},
  author={Bailo, Oleksandr and Rameau, Francois and Joo, Kyungdon and Park, Jinsun and Bogdan, Oleksandr and Kweon, In So},
  journal={Pattern Recognition Letters},
  volume={106},
  pages={53--60},
  year={2018},
  publisher={Elsevier}
}
"""

#!pip install opencv-python==3.4.2.17 opencv-contrib-python==3.4.2.17

#!pip install pyro-ppl

#from google.colab import drive
#drive.mount('/content/drive')

# this code section is from: https://github.com/BAILOOL/ANMS-Codes
# Adaptive Non-Maximal supression is used to evenly distribute feature points
import cv2 as cv
import sys
import numpy as np
import matplotlib.pyplot as plt
import argparse
from random import shuffle
import logging

import torch

import pyro
import pyro.distributions as dist
import pyro.poutine as poutine
from pyro.infer import MCMC, NUTS
import pptk
#from google.colab.patches import cv2_imshow
import math
import copy
from ssc import *
from helper import *
import open3d as o3d
import os

cuda = False

def ssc(keypoints, num_ret_points, tolerance, cols, rows):
    exp1 = rows + cols + 2 * num_ret_points
    exp2 = 4 * cols + 4 * num_ret_points + 4 * rows * num_ret_points + rows * rows + cols * cols - \
           2 * rows * cols + 4 * rows * cols * num_ret_points
    exp3 = math.sqrt(exp2)
    exp4 = num_ret_points - 1

    sol1 = -round(float(exp1 + exp3) / exp4)  # first solution
    sol2 = -round(float(exp1 - exp3) / exp4)  # second solution

    high = sol1 if (sol1 > sol2) else sol2  # binary search range initialization with positive solution
    low = math.floor(math.sqrt(len(keypoints) / num_ret_points))

    prev_width = -1
    selected_keypoints = []
    result_list = []
    result = []
    complete = False
    k = num_ret_points
    k_min = round(k - (k * tolerance))
    k_max = round(k + (k * tolerance))

    while not complete:
        width = low + (high - low) / 2
        if width == prev_width or low > high:  # needed to reassure the same radius is not repeated again
            result_list = result  # return the keypoints from the previous iteration
            break

        c = width / 2  # initializing Grid
        num_cell_cols = int(math.floor(cols / c))
        num_cell_rows = int(math.floor(rows / c))
        covered_vec = [[False for _ in range(num_cell_cols + 1)] for _ in range(num_cell_rows + 1)]
        result = []

        for i in range(len(keypoints)):
            row = int(math.floor(keypoints[i].pt[1] / c))  # get position of the cell current point is located at
            col = int(math.floor(keypoints[i].pt[0] / c))
            if not covered_vec[row][col]:  # if the cell is not covered
                result.append(i)
                # get range which current radius is covering
                row_min = int((row - math.floor(width / c)) if ((row - math.floor(width / c)) >= 0) else 0)
                row_max = int(
                    (row + math.floor(width / c)) if (
                            (row + math.floor(width / c)) <= num_cell_rows) else num_cell_rows)
                col_min = int((col - math.floor(width / c)) if ((col - math.floor(width / c)) >= 0) else 0)
                col_max = int(
                    (col + math.floor(width / c)) if (
                            (col + math.floor(width / c)) <= num_cell_cols) else num_cell_cols)
                for rowToCov in range(row_min, row_max + 1):
                    for colToCov in range(col_min, col_max + 1):
                        if not covered_vec[rowToCov][colToCov]:
                            # cover cells within the square bounding box with width w
                            covered_vec[rowToCov][colToCov] = True

        if k_min <= len(result) <= k_max:  # solution found
            result_list = result
            complete = True
        elif len(result) < k_min:
            high = width - 1  # update binary search range
        else:
            low = width + 1
        prev_width = width

    for i in range(len(result_list)):
        selected_keypoints.append(keypoints[result_list[i]])

    return selected_keypoints

"""First, load left and right (multiple images later on)"""

fx = 499.70
fy = 502.22
cx = 315.28
cy = 240.62
K = np.array([[fx , 0 , cx]  ,[0  ,fy , cy]  ,[0  ,0  ,1]])

dim = (1600,1200)

left_orig2 = cv.imread("left.jpg")
left_orig = cv.GaussianBlur(left_orig2,(111,111),10)
cv.imwrite("left_orig.jpg",left_orig)

left = cv.imread("left.jpg",cv.IMREAD_GRAYSCALE)
right = cv.imread("right.jpg",cv.IMREAD_GRAYSCALE)

left = cv.GaussianBlur(left,(5,5),1)
right = cv.GaussianBlur(right,(5,5),1)


left = cv.resize(left, dim, interpolation = cv.INTER_AREA)
right = cv.resize(right, dim, interpolation = cv.INTER_AREA)
left_orig = cv.resize(left_orig, dim, interpolation = cv.INTER_AREA)
left_orig2 = cv.resize(left_orig2, dim, interpolation = cv.INTER_AREA)

cv.imwrite("plot-img.jpg",left_orig2)

"""For all images, Extract feature points"""


sift = cv.xfeatures2d.SIFT_create()

# find the keypoints with ORB
# compute the descriptors with ORB
kpL = sift.detect(left,None)

shuffle(kpL)  # simulating sorting by score with random shuffle
s_kpL = ssc(kpL, 10000, 0.01, left.shape[1], left.shape[0])
#s_kpL = kpL

s_kpL,desL = sift.compute(left,s_kpL)

# draw only keypoints location, not size and orientation
left2 = cv.drawKeypoints(left, s_kpL, None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

siftR = cv.xfeatures2d.SIFT_create()

# find the keypoints with ORB
kpR = sift.detect(right,None)

shuffle(kpR)
s_kpR = ssc(kpR, 10000, 0.01, right.shape[1], right.shape[0])
#s_kpR = kpR

s_kpR,desR = sift.compute(right,s_kpR)


# draw only keypoints location,not size and orientation
right2 = cv.drawKeypoints(right, s_kpR, None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

desL = np.float32(desL)
desR = np.float32(desR)

print("got points" + str(desL.shape))

# FLANN parameters
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)
search_params = dict(checks=50)   # or pass empty dictionary

#flann = cv.FlannBasedMatcher(index_params,search_params,crossCheck = True)
flann = cv.BFMatcher()
# Sort them in the order of their distance.
matches = flann.knnMatch(desL,desR,k=2)
# Need to draw only good matches, so create a mask
matchesMask = [[0,0] for i in range(len(matches))]
# ratio test as per Lowe's paper
newmatches = []
for i,(m,n) in enumerate(matches):
    if m.distance < 0.7*n.distance: # == 서로 비슷하면
        matchesMask[i]=[1,0]
        newmatches.append([m,n])        


draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = matchesMask,
                   flags = cv.DrawMatchesFlags_DEFAULT)

print ("knn matches:" + str(len(newmatches)))

img3 = cv.drawMatchesKnn(left2,s_kpL,right2,s_kpR,matches,None,**draw_params)
cv.imwrite("img.jpg",img3)

"""After getting matching points, set up Matrix D"""

# D = [[z11x11 z12x12 ... z1nx1n] , [z21x21 z22x22 ... z2nx2n]]

# Initialize lists
list_kpL = []
list_kpR = []

# For each match...
sumx = 0
sumy = 0
for mat_2 in newmatches:
    mat = mat_2[0]
    # Get the matching keypoints for each of the images
    img1_idx = mat.queryIdx
    img2_idx = mat.trainIdx

    # x - columns
    # y - rows
    # Get the coordinates
    (x1, y1) = s_kpL[img1_idx].pt
    (x2, y2) = s_kpR[img2_idx].pt

    # Append to each list
    list_kpL.append((x1, y1,1))
    list_kpR.append((x2, y2,1))

ptsL = np.array(list_kpL)
ptsR = np.array(list_kpR)

#ptsL ptsR normalization 실행
L_mean = (sum(ptsL)/len(ptsL))
R_mean = (sum(ptsR)/len(ptsR))

ptsL = [(x - L_mean) for x in ptsL]
ptsR = [(x - R_mean) for x in ptsR]

ptsL = np.array(ptsL)
ptsR = np.array(ptsR)

#ptsL = cv.undistortPoints(ptsL, K,None)
#ptsR = cv.undistortPoints(ptsR, K,None)

F, mask = cv.findFundamentalMat(ptsL,ptsR,cv.FM_LMEDS)

# We select only inlier points

ptsLtmp = ptsL[mask.ravel()==1]
ptsRtmp = ptsR[mask.ravel()==1] 

# // MCMC 로 바꿔버릴 수 있다

print("fundamental matrix Mask"+str(ptsL.shape))



"""After obtaining matches from two images, Pyro will be used to do projective factorization"""

torch.cuda.is_available()

extr_L = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])

#F = torch.from_numpy(F).cuda()


E = np.matmul(np.matmul(np.transpose(K), F), K)

print(K)

ptsL2 = ptsL[:,0:2]
ptsR2 = ptsR[:,0:2]
ptsL2tmp = ptsLtmp[:,0:2]
ptsR2tmp = ptsRtmp[:,0:2]

# Recoverpose uses Singular Value Decomposition in least_squares way. Outliers are masked
retval, Rot, t, mask = cv.recoverPose(E, ptsL2tmp, ptsR2tmp, K)

#ptsL = ptsL[mask.ravel()!=0]
#ptsR = ptsR[mask.ravel()!=0]

ptsL2 = ptsL[:,0:2]
ptsR2 = ptsR[:,0:2]


extr_R = np.concatenate((Rot,t),axis = 1)

print("Rotation and translation")
print(Rot)
print(t)

P_L = np.matmul(K,extr_L)
P_R = np.matmul(K,extr_R)

print(P_L)
print(P_R)

ptsL2 = np.transpose(ptsL2)
ptsR2 = np.transpose(ptsR2)

#Projects 2D points into 3D space by P_R and P_L, and uses least-square matching...
PTS = cv.triangulatePoints(P_R,P_L,ptsR2,ptsL2)

PTS /= PTS[3]
print(PTS.shape)
#U,S,V = torch.svd(D, some=False, compute_uv=True, out=None)
#print(U.shape)

P = torch.from_numpy(np.concatenate((P_L,P_R),axis = 0)) #construction of Camera Matrices
P_bef = P
if(cuda):
    P.cuda()

D_list = [ptsL,ptsR]
Darr = np.array(D_list).reshape(6,-1)


p = PTS[3,:]
xn = PTS[0,:] 
yn = PTS[1,:] 
zn = PTS[2,:] 


xyz = []
xyzH = []
colors = []
L_pos = []
idx = 0
print(left_orig.shape)

maxwidth = left_orig.shape[0]
maxheight = left_orig.shape[1]
numfilter = 0
for (i, j, k) in zip(xn, yn, zn):
    posx = ptsL2[0][idx] + L_mean[0]
    posy = ptsL2[1][idx] + L_mean[1]
    
    if(np.sqrt(i*i + j*j + k*k) < 100 and posx < maxheight and posy < maxwidth and posx >= 0 and posy >= 0):

        L_pos.append([posx,posy])
        xyz.append([i,j,k])
        xyzH.append([i,j,k,1])
        
        col = left_orig[int(posy),int(posx)].tolist()
        B = col[0]
        G = col[1]
        R = col[2]
        col = [R,G,B]
        col = [float(i)/255.0 for i in col]
        colors.append(col)
    else:
        numfilter += 1
    idx += 1

print("Filtered:" + str(numfilter))

pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(xyz)
pcd.colors = o3d.utility.Vector3dVector(colors)
o3d.io.write_point_cloud("sync.ply", pcd)
pcd_load = o3d.io.read_point_cloud("sync.ply")
xyz_load = np.asarray(pcd_load.points)
o3d.visualization.draw_geometries([pcd_load],width = 1000,height = 1000)




xyzH = np.array(xyzH)

# x = PX 이용해서 나타내보면?
print()
xyzH = np.transpose(np.array(xyzH))

rec_points_L = np.transpose(np.matmul(P_L,xyzH))
rec_points_R = np.transpose(np.matmul(P_R,xyzH))
rec_points_L = (rec_points_L)/rec_points_L[:,2:3] + L_mean
rec_points_R = (rec_points_R)/rec_points_R[:,2:3] + R_mean
rec_points_L = rec_points_L[:,0:2]
rec_points_R = rec_points_R[:,0:2]

print(rec_points_L.shape)


#Reprojection 에러들을 확인해보자.
L_pos = np.array(L_pos)
im = plt.imread("plot-img.jpg")
implot = plt.imshow(im)
plt.scatter(rec_points_L[:,0],rec_points_L[:,1], c='r', s=5)
plt.scatter(L_pos[:,0],L_pos[:,1], c='g', s=5)
plt.scatter(rec_points_R[:,0],rec_points_R[:,1], c='b', s=2)

plt.savefig('reproject-L.png')
#plt.show()



print("bp")

# x = PX

# sample P and X from some distribution
# observe x = PX


# Generate P and X using triangulation, getting somewhat good prior to begin with


# Now given a very good prior that utilizes triangulation, Bundle adjustment may be used in order to further reduce reprojection error.


# Pyro Code Start
from pyro.optim import Adam
from pyro.infer import SVI, Trace_ELBO
import pyro.distributions as dist
import torch.distributions.constraints as constraints
import pyro.contrib.autoguide as autoguide
# this is for running the notebook in our testing framework
torch.set_default_tensor_type('torch.FloatTensor')

smoke_test = ('CI' in os.environ)
pyro.enable_validation(True)
pyro.clear_param_store()

#Define Number of steps to be used
n_steps = 2 if smoke_test else 10000


#Loading Necessary Parameters
R_prior = torch.from_numpy(Rot)
t_prior = torch.from_numpy(t)
D_prior = torch.from_numpy(Darr)
prior = torch.from_numpy(PTS)

#From R try to extract alpha,beta,gamma
alpha_prior     = math.atan2(R_prior[2,1],R_prior[2,2]) 
beta_prior      = math.atan2(-R_prior[2,0],math.sqrt(math.pow(R_prior[2,1],2) + math.pow(R_prior[2,2],2))) 
gamma_prior     = math.atan2(R_prior[1,0],R_prior[0,0]) 



if(cuda):
    D.cuda()
    R.cuda()
    t.cuda()
    torch.set_default_tensor_type('torch.cuda.FloatTensor')
    prior.cuda()

#Pre-made Zeros or Ones distributions
P_ones = torch.ones([P.shape[0],P.shape[1]])
prior_sigma = 0.03*torch.ones([4,prior.shape[1]])
ones_sigma = torch.ones([D_prior.shape[0],D_prior.shape[1]])

if(cuda):
    P_ones.cuda()
    prior.cuda()
    prior_sigma.cuda()
    ones_sigma.cuda()


def model(data):
    # define the hyperparameters that control the beta prior

    #P0 = torch.zeros([P.shape[0],P.shape[1]])
    #X0 = torch.zeros([prior.shape[0],prior.shape[1]])
    X0 = prior

    #TODO: R t constraints 추가해서 조금 더 현실적으로 ㄱㄱ
    #Properties of P --> P = K * Extr
    #Extrinsic Sampling 하기
    alpha = pyro.sample('alpha', dist.Normal(alpha_prior,0.01))
    beta = pyro.sample('beta', dist.Normal(beta_prior,0.01))
    gamma = pyro.sample('gamma', dist.Normal(gamma_prior,0.01))

    x_t = pyro.sample('x_t', dist.Normal(t_prior[0],0.01))
    y_t = pyro.sample('y_t', dist.Normal(t_prior[1],0.01))
    z_t = pyro.sample('z_t', dist.Normal(t_prior[2],0.01))
    #Construct P using info sampled above
    alpha_mat = torch.tensor([   [1.,0.,0.],                            [0.,math.cos(alpha),-math.sin(alpha)],  [0.,math.sin(alpha),math.cos(alpha)]])
    beta_mat = torch.tensor ([   [math.cos(beta),0.,math.sin(beta)],    [0.,1.,0.],                             [-math.sin(beta),0.,math.cos(beta)]])
    gamma_mat = torch.tensor([   [math.cos(gamma),-math.sin(gamma),0.], [math.sin(gamma),math.cos(gamma),0.],   [0.,0.,1.]])

    R = torch.mm(torch.mm(alpha_mat,beta_mat),gamma_mat)    #3x3
    t = torch.tensor([[x_t],[y_t],[z_t]]).float()                     #3x1
    extr_R = torch.cat((R,t),1)                             #3x4

    P_R = torch.mm(torch.from_numpy(K).float(),extr_R)
    Px =  torch.from_numpy(np.concatenate((P_L,P_R),axis = 0)).float()



    X_x_axis = pyro.plate("X_x_axis", X0.shape[1])
    X_y_axis = pyro.plate("X_y_axis", X0.shape[0])
    #Px = P
    with X_x_axis, X_y_axis:
        X = pyro.sample('X', dist.Normal(X0, prior_sigma))
        if(cuda):
            X.cuda()

    res = torch.mm(Px,X)# reproject 를 한 것.
    if(cuda):
        res.cuda()
    #res = res/res[3]
    D_x_axis = pyro.plate("D_x_axis", data.shape[1])
    D_y_axis = pyro.plate("D_y_axis", data.shape[0])
    with D_x_axis,D_y_axis:
        pyro.sample('obs', dist.Normal(res,ones_sigma), obs=data)

P_nil = torch.tensor(600*np.ones((P.shape[0],P.shape[1]))).cuda()
prior_nil = torch.tensor(np.ones((prior.shape[0],prior.shape[1]))).cuda()

#guide = autoguide.AutoDiagonalNormal(model)
def guide(data):
    # define the hyperparameters that control the beta prior


    X_x_axis = pyro.plate("X_x_axis", prior.shape[1])
    X_y_axis = pyro.plate("X_y_axis", prior.shape[0])

    #TODO: R t constraints 추가해서 조금 더 현실적으로 ㄱㄱ
    X_q = pyro.param("X_q", torch.zeros([prior.shape[0],prior.shape[1]]))

    alpha_q =       pyro.param("alpha_q",torch.tensor(alpha_prior))
    beta_q =        pyro.param("beta_q",torch.tensor(beta_prior))
    gamma_q =       pyro.param("gamma_q",torch.tensor(gamma_prior))
    x_t_q =         pyro.param("x_t_q",torch.tensor(t_prior[0]))
    y_t_q =         pyro.param("y_t_q",torch.tensor(t_prior[1]))
    z_t_q =         pyro.param("z_t_q",torch.tensor(t_prior[2]))

    alpha = pyro.sample('alpha', dist.Normal(alpha_q,1))
    beta = pyro.sample('beta', dist.Normal(beta_q,1))
    gamma = pyro.sample('gamma', dist.Normal(gamma_q,1))

    x_t = pyro.sample('x_t', dist.Normal(x_t_q,1))
    y_t = pyro.sample('y_t', dist.Normal(y_t_q,1))
    z_t = pyro.sample('z_t', dist.Normal(z_t_q,1))
    #Construct P using info sampled above
    alpha_mat = torch.tensor([   [1.,0.,0.],                            [0.,math.cos(alpha),-math.sin(alpha)],  [0.,math.sin(alpha),math.cos(alpha)]])
    beta_mat = torch.tensor ([   [math.cos(beta),0.,math.sin(beta)],    [0.,1.,0.],                             [-math.sin(beta),0.,math.cos(beta)]])
    gamma_mat = torch.tensor([   [math.cos(gamma),-math.sin(gamma),0.], [math.sin(gamma),math.cos(gamma),0.],   [0.,0.,1.]])

    R = torch.mm(torch.mm(alpha_mat,beta_mat),gamma_mat)    #3x3
    t = torch.tensor([[x_t],[y_t],[z_t]]).float()                     #3x1
    extr_R = torch.cat((R,t),1)                             #3x4

    P_R = torch.mm(torch.from_numpy(K).float(),extr_R)
    Px =  torch.from_numpy(np.concatenate((P_L,P_R),axis = 0)).float()

    if(cuda):
        X_q.cuda()
        Px.cuda()


    
    #Px = P
    with X_x_axis, X_y_axis:
        X = pyro.sample('X', dist.Normal(X_q, prior_sigma))
        div = X[3,:].clone()
        X /= div
        if(cuda):
            X.cuda()

    res = torch.mm(Px,X) # reproject 를 한 것.
    if(cuda):
        res.cuda()
    #res = res/res[3]
    D_x_axis = pyro.plate("D_x_axis", data.shape[1])
    D_y_axis = pyro.plate("D_y_axis", data.shape[0])
    with D_x_axis,D_y_axis:
        pyro.sample('obs', dist.Normal(res,ones_sigma), obs=data)

    #res 가 sample 결과고, 비교대상이 D <- observation
# setup the optimizer
loss = pyro.infer.JitTraceGraph_ELBO()

adam_params = {"lr": 0.005, "betas": (0.95, 0.999)}

optimizer = Adam(adam_params)

#guide = autoguide.AutoDiagonalNormal(model)
svi = SVI(model, guide, optimizer, loss=Trace_ELBO())

loss = pyro.infer.JitTraceGraph_ELBO()
#svi = SVI(model, guide, optimizer, loss)


losses = np.empty(n_steps)
for step in range(n_steps):
    losses[step] = svi.step(D_prior)
    if step % 100 == 0:
        print(f"step: {step:>5}, ELBO loss: {losses[step]:.2f}")
    #return res # 각 사진 위에 xy 지점들

posterior = pyro.infer.Predictive
X = pyro.param("X_q")

alpha =       pyro.param("alpha_q")
beta =        pyro.param("beta_q")
gamma =       pyro.param("gamma_q")
x_t =         pyro.param("x_t_q")
y_t =         pyro.param("y_t_q")
z_t =         pyro.param("z_t_q")
alpha_mat = torch.tensor([   [1.,0.,0.],                            [0.,math.cos(alpha),-math.sin(alpha)],  [0.,math.sin(alpha),math.cos(alpha)]])
beta_mat = torch.tensor ([   [math.cos(beta),0.,math.sin(beta)],    [0.,1.,0.],                             [-math.sin(beta),0.,math.cos(beta)]])
gamma_mat = torch.tensor([   [math.cos(gamma),-math.sin(gamma),0.], [math.sin(gamma),math.cos(gamma),0.],   [0.,0.,1.]])

R = torch.mm(torch.mm(alpha_mat,beta_mat),gamma_mat)    #3x3
t = torch.tensor([[x_t],[y_t],[z_t]]).float()                     #3x1
extr_R = torch.cat((R,t),1)                             #3x4

P_R = torch.mm(torch.from_numpy(K).float(),extr_R)
P_after =  torch.from_numpy(np.concatenate((P_L,P_R),axis = 0)).float()

print(type(X))

#prior vs X 비교하자   --- D-2D  prior3d

Reproject_before = torch.mm(P_bef,prior)
Reproject_after  = torch.mm(P_after,X)

dist_prior1 = torch.dist(D_prior,Reproject_before,2)
dist_prior2 = torch.dist(D_prior,Reproject_after,2)

print("distance prior: " + str(dist_prior1) + " --- inferred: " + str(dist_prior2))





'''
#torch.set_default_tensor_type('torch.cuda.FloatTensor')
logging.basicConfig(format='%(message)s', level=logging.INFO)
pyro.enable_validation(__debug__)
pyro.set_rng_seed(0)

#device = 'cuda:0'

prior = torch.from_numpy(PTS)#.cuda()
prior_sigma = 0.03*torch.ones([4,D.shape[1]])#.cuda()
ones_sigma = torch.ones([D.shape[0],D.shape[1]])#.cuda()
# D = m x n,        P = 3m x 4,         X = 4 x n
one = torch.ones(1)
zeros = torch.zeros(1)
def model(truth):

    # x = PX 
    # P 와 X 잘 맞으면, PX --> 사진에 어떻게 보이는지.

    Px = pyro.sample('P', dist.Normal(P, torch.ones([D.shape[0],4])))
    #Px = P
    X = pyro.sample('X', dist.Normal(prior, prior_sigma))
    res = torch.mm(Px,X)#.cuda() # reproject 를 한 것.
    res = res/res[3]

    distance = torch.dist(truth,res,2)
    
    y = pyro.sample('y', dist.Normal(distance,one), obs=zeros)
    return y


    #res 가 sample 결과고, 비교대상이 D <- observation

    #return res # 각 사진 위에 xy 지점들

#def conditioned_model(model, sigma, y):
#    return poutine.condition(model, data={"obs": y})(sigma)

nuts_kernel = NUTS(model, adapt_step_size=True)
mcmc = MCMC(nuts_kernel,
            num_samples=1000,
            warmup_steps=1000,
             mp_context="spawn")
mcmc_run = mcmc.run(D)

#MCMC 는 느리므로, SVI 를 이용해보자?

#posterior = EmpiricalMarginal(mcmc_run, 'beta')
res = mcmc.get_samples()


#P = res['P'].cpu()
X = res['X'].mean(0).cpu()
'''
# Pyro Code End

# 89 포인트
p   = X[3,:]
xn  = X[0,:] 
yn  = X[1,:] 
zn  = X[2,:] 

xn = torch.div(xn, p).tolist()
yn = torch.div(yn, p).tolist()
zn = torch.div(zn, p).tolist()

x = []
y = []
z = []
xyz = []
colors = []
idx = 0

numfilter = 0
num_imgconst = 0
for (i, j, k) in zip(xn, yn, zn):
    posx = ptsL2[0][idx] + L_mean[0]
    posy = ptsL2[1][idx] + L_mean[1]
    
    img_constraint = posx < maxwidth and posy < maxheight and posx >= 0 and posy >= 0
    if(not img_constraint):
        num_imgconst += 1

    if(np.sqrt(i*i + j*j + k*k) < 100 and img_constraint):
        #if(np.sqrt(i*i + j*j + k*k) < 30):
        x.append(i)
        y.append(j)
        z.append(k)
        
        xyz.append([i,j,k])

        col = left_orig[int(posy),int(posx)].tolist()
        B = col[0]
        G = col[1]
        R = col[2]
        col = [R,G,B]
        col = [float(i)/255.0 for i in col]
        colors.append(col)
    else:
        x.append(i)
        y.append(j)
        z.append(k)
        xyz.append([i,j,k])
        colors.append([0.0,0.0,0.0])
        numfilter += 1
    idx += 1

print("Filtered:" + str(numfilter))
print("Image constraint :" + str(num_imgconst))


pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(xyz)
pcd.colors = o3d.utility.Vector3dVector(colors)
o3d.io.write_point_cloud("sync.ply", pcd)
pcd_load = o3d.io.read_point_cloud("sync.ply")
xyz_load = np.asarray(pcd_load.points)
o3d.visualization.draw_geometries([pcd_load],width = 1000,height = 1000)

print("bp")


#Now to begin matching by interpolation

#Given a set of points, I will try to use voronoi partitioning. 

# 

